{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "372c7d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from constants import (\n",
    "    DB_NAME_NEWS, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e356b24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 0 rows\n",
      "Rows processed: 0\n",
      "Rows discarded (updateDate not empty but preprocessed is False): 0\n"
     ]
    }
   ],
   "source": [
    "with sqlite3.connect(DB_NAME_NEWS) as conn:\n",
    "    cur = conn.cursor()\n",
    "    data = cur.execute(\"\"\"\n",
    "                        SELECT \n",
    "                            url,\n",
    "                            description,\n",
    "                            score\n",
    "                        FROM \n",
    "                            news\n",
    "                        WHERE\n",
    "                            updateDate = ''\n",
    "                        AND\n",
    "                            preprocessed = FALSE\n",
    "                    \"\"\") \\\n",
    "                .fetchall()\n",
    "    print(f\"Read {len(data)} rows\")\n",
    "    df = pd.DataFrame(data, \n",
    "                    columns=['url', \n",
    "                             'desc', \n",
    "                             'score'\n",
    "                             ])\n",
    "    # Filter out empty descriptions\n",
    "    df_with_desc = df[df[\"desc\"] != \"\"].reset_index(drop=True)\n",
    "    df_with_desc[\"score\"] = df_with_desc[\"score\"] + 1\n",
    "\n",
    "    # Extract 1 random row from each 'desc' groupby\n",
    "    in_index_one_random_from_groups = df_with_desc.groupby(\"desc\") \\\n",
    "                                        .sample(n=1, weights=\"score\").index\n",
    "    out_index_one_random_from_groups = df_with_desc.index.difference(in_index_one_random_from_groups)\n",
    "    # Filter out duplicates\n",
    "    urls_to_preprocess = df_with_desc.iloc[in_index_one_random_from_groups][\"url\"].tolist()\n",
    "    urls_to_preprocess = tuple((x, ) for x in urls_to_preprocess)\n",
    "    # Filter out fully processed rows\n",
    "    urls_to_only_update = df_with_desc.iloc[out_index_one_random_from_groups][\"url\"].tolist() + df.loc[df[\"desc\"] == \"\", \"url\"].tolist()\n",
    "    urls_to_only_update = tuple((x, ) for x in urls_to_only_update)\n",
    "\n",
    "    cur.executemany(\"\"\"\n",
    "        UPDATE  \n",
    "            news\n",
    "        SET\n",
    "            preprocessed = TRUE,\n",
    "            updateDate = DATETIME('now', 'localtime', 'utc')\n",
    "        WHERE\n",
    "            url = ?\n",
    "    \"\"\", urls_to_preprocess)\n",
    "    conn.commit()\n",
    "    cur.executemany(\"\"\"\n",
    "        UPDATE  \n",
    "            news\n",
    "        SET\n",
    "            updateDate = DATETIME('now', 'localtime', 'utc')\n",
    "        WHERE\n",
    "            url = ?\n",
    "    \"\"\", urls_to_only_update)\n",
    "    conn.commit()\n",
    "print(f\"Rows processed: {len(urls_to_preprocess)}\")\n",
    "print(f\"Rows discarded (updateDate not empty but preprocessed is False): {len(urls_to_only_update)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5d3558",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
